import json
import logging
from datetime import datetime
from typing import Annotated, Any

from fastmcp import Context, FastMCP
from pydantic import Field
from qdrant_client import models

from mcp_server_qdrant.common.filters import make_indexes
from mcp_server_qdrant.common.func_tools import make_partial_function
from mcp_server_qdrant.common.wrap_filters import wrap_filters
from mcp_server_qdrant.embeddings.factory import create_embedding_provider
from mcp_server_qdrant.qdrant import ArbitraryFilter, Entry, Metadata, QdrantConnector
from mcp_server_qdrant.settings import (
    EmbeddingProviderSettings,
    QdrantSettings,
    ToolSettings,
)
from mcp_server_qdrant.system_monitor import UniversalQdrantMonitor
from mcp_server_qdrant.storage_optimizer import QdrantStorageOptimizer

logger = logging.getLogger(__name__)


# FastMCP is an alternative interface for declaring the capabilities
# of the server. Its API is based on FastAPI.
class QdrantMCPServer(FastMCP):
    """
    A MCP server for Qdrant.
    """

    def __init__(
        self,
        tool_settings: ToolSettings,
        qdrant_settings: QdrantSettings,
        embedding_provider_settings: EmbeddingProviderSettings,
        name: str = "mcp-server-qdrant",
        instructions: str | None = None,
        **settings: Any,
    ):
        self.tool_settings = tool_settings
        self.qdrant_settings = qdrant_settings
        self.embedding_provider_settings = embedding_provider_settings

        self.embedding_provider = create_embedding_provider(embedding_provider_settings)
        self.qdrant_connector = QdrantConnector(
            qdrant_settings.location,
            qdrant_settings.api_key,
            qdrant_settings.collection_name,
            self.embedding_provider,
            qdrant_settings.local_path,
            make_indexes(qdrant_settings.filterable_fields_dict()),
        )
        
        # åˆå§‹åŒ–é€šç”¨ç³»çµ±ç›£æ§å™¨
        self.system_monitor = UniversalQdrantMonitor(
            self.qdrant_connector._client,
            qdrant_settings.location
        )
        
        # åˆå§‹åŒ–å„²å­˜å„ªåŒ–å·¥å…·
        self.storage_optimizer = QdrantStorageOptimizer(
            self.qdrant_connector._client
        )

        super().__init__(name=name, instructions=instructions, **settings)

        self.setup_tools()

    def format_entry(self, entry: Entry) -> str:
        """
        Feel free to override this method in your subclass to customize the format of the entry.
        """
        entry_metadata = json.dumps(entry.metadata) if entry.metadata else ""
        return f"<entry><content>{entry.content}</content><metadata>{entry_metadata}</metadata></entry>"

    def setup_tools(self):
        """
        Register the tools in the server.
        """

        async def store(
            ctx: Context,
            information: Annotated[str, Field(description="Text to store")],
            collection_name: Annotated[
                str, Field(description="The collection to store the information in")
            ] = "default",
            # The `metadata` parameter is defined as non-optional, but it can be None.
            # If we set it to be optional, some of the MCP clients, like Cursor, cannot
            # handle the optional parameter correctly.
            metadata: Annotated[
                Metadata | None,
                Field(
                    description="Extra metadata stored along with memorised information. Any json is accepted."
                ),
            ] = None,
        ) -> str:
            """
            Store some information in Qdrant.
            :param ctx: The context for the request.
            :param information: The information to store.
            :param metadata: JSON metadata to store with the information, optional.
            :param collection_name: The name of the collection to store the information in, optional. If not provided,
                                    the default collection is used.
            :return: A message indicating that the information was stored.
            """
            await ctx.debug(f"Storing information {information} in Qdrant")

            entry = Entry(content=information, metadata=metadata)

            await self.qdrant_connector.store(entry, collection_name=collection_name)
            if collection_name:
                return f"Remembered: {information} in collection {collection_name}"
            return f"Remembered: {information}"

        async def find(
            ctx: Context,
            query: Annotated[str, Field(description="What to search for")],
            collection_name: Annotated[
                str, Field(description="The collection to search in")
            ] = "default",
            query_filter: ArbitraryFilter | None = None,
        ) -> list[str]:
            """
            Find memories in Qdrant.
            :param ctx: The context for the request.
            :param query: The query to use for the search.
            :param collection_name: The name of the collection to search in, optional. If not provided,
                                    the default collection is used.
            :param query_filter: The filter to apply to the query.
            :return: A list of entries found.
            """

            # Log query_filter
            await ctx.debug(f"Query filter: {query_filter}")

            query_filter = models.Filter(**query_filter) if query_filter else None

            await ctx.debug(f"Finding results for query {query}")

            entries = await self.qdrant_connector.search(
                query,
                collection_name=collection_name,
                limit=self.qdrant_settings.search_limit,
                query_filter=query_filter,
            )
            if not entries:
                return [f"No information found for the query '{query}'"]
            content = [
                f"Results for the query '{query}'",
            ]
            for entry in entries:
                content.append(self.format_entry(entry))
            return content

        find_foo = find
        store_foo = store

        filterable_conditions = (
            self.qdrant_settings.filterable_fields_dict_with_conditions()
        )

        if len(filterable_conditions) > 0:
            find_foo = wrap_filters(find_foo, filterable_conditions)
        elif not self.qdrant_settings.allow_arbitrary_filter:
            find_foo = make_partial_function(find_foo, {"query_filter": None})

        if self.qdrant_settings.collection_name:
            find_foo = make_partial_function(
                find_foo, {"collection_name": self.qdrant_settings.collection_name}
            )
            store_foo = make_partial_function(
                store_foo, {"collection_name": self.qdrant_settings.collection_name}
            )

        self.tool(
            find_foo,
            name="qdrant-find",
            description=self.tool_settings.tool_find_description,
        )

        if not self.qdrant_settings.read_only:
            # Those methods can modify the database
            self.tool(
                store_foo,
                name="qdrant-store",
                description=self.tool_settings.tool_store_description,
            )

            # æ–°å¢åˆªé™¤æ–‡æª”å·¥å…·
            async def delete_documents(
                ctx: Context,
                query: Annotated[str, Field(description="æœå°‹è¦åˆªé™¤çš„æ–‡æª”")],
                collection_name: Annotated[
                    str, Field(description="è¦åˆªé™¤æ–‡æª”çš„ collection åç¨±")
                ] = "default",
                confirm_delete: Annotated[
                    bool, Field(description="ç¢ºèªåˆªé™¤æ“ä½œï¼Œå¿…é ˆè¨­ç‚º True")
                ] = False,
                limit: Annotated[
                    int, Field(description="æœ€å¤šåˆªé™¤çš„æ–‡æª”æ•¸é‡")
                ] = 10,
            ) -> str:
                """
                åˆªé™¤ç¬¦åˆæœå°‹æ¢ä»¶çš„æ–‡æª”ã€‚éœ€è¦æ˜ç¢ºç¢ºèªæ‰èƒ½åŸ·è¡Œã€‚
                """
                await ctx.debug(f"Deleting documents matching '{query}' in collection '{collection_name}'")
                
                result = await self.qdrant_connector.delete_documents(
                    query=query,
                    collection_name=collection_name,
                    limit=limit,
                    confirm_delete=confirm_delete,
                )
                
                if "error" in result:
                    return f"éŒ¯èª¤: {result['error']}"
                
                return f"{result['message']} (åœ¨ collection '{result['collection_name']}')"

            # æ–°å¢åˆªé™¤ collection å·¥å…·
            async def delete_collection(
                ctx: Context,
                collection_name: Annotated[
                    str, Field(description="è¦åˆªé™¤çš„ collection åç¨±")
                ] = "default",
                confirm_delete: Annotated[
                    bool, Field(description="ç¢ºèªåˆªé™¤æ“ä½œï¼Œå¿…é ˆè¨­ç‚º True")
                ] = False,
            ) -> str:
                """
                åˆªé™¤æ•´å€‹ collection åŠå…¶æ‰€æœ‰æ–‡æª”ã€‚éœ€è¦æ˜ç¢ºç¢ºèªæ‰èƒ½åŸ·è¡Œã€‚
                """
                await ctx.debug(f"Deleting collection '{collection_name}'")
                
                result = await self.qdrant_connector.delete_collection(
                    collection_name=collection_name,
                    confirm_delete=confirm_delete,
                )
                
                if "error" in result:
                    return f"éŒ¯èª¤: {result['error']}"
                
                return result["message"]

            # æ–°å¢æ¬ç§»æ–‡æª”å·¥å…·
            async def move_documents(
                ctx: Context,
                query: Annotated[str, Field(description="æœå°‹è¦æ¬ç§»çš„æ–‡æª”")],
                source_collection: Annotated[
                    str, Field(description="ä¾†æº collection åç¨±")
                ] = "default",
                target_collection: Annotated[
                    str, Field(description="ç›®æ¨™ collection åç¨±")
                ] = "default",
                confirm_move: Annotated[
                    bool, Field(description="ç¢ºèªæ¬ç§»æ“ä½œï¼Œå¿…é ˆè¨­ç‚º True")
                ] = False,
                limit: Annotated[
                    int, Field(description="æœ€å¤šæ¬ç§»çš„æ–‡æª”æ•¸é‡")
                ] = 10,
            ) -> str:
                """
                æ¬ç§»æ–‡æª”å¾ä¸€å€‹ collection åˆ°å¦ä¸€å€‹ collectionã€‚éœ€è¦æ˜ç¢ºç¢ºèªæ‰èƒ½åŸ·è¡Œã€‚
                """
                await ctx.debug(f"Moving documents matching '{query}' from '{source_collection}' to '{target_collection}'")
                
                result = await self.qdrant_connector.move_documents(
                    query=query,
                    source_collection=source_collection,
                    target_collection=target_collection,
                    limit=limit,
                    confirm_move=confirm_move,
                )
                
                return f"{result['message']}"

            # æ–°å¢æ›´æ–° metadata å·¥å…·
            async def update_metadata(
                ctx: Context,
                query: Annotated[str, Field(description="æœå°‹è¦æ›´æ–°çš„æ–‡æª”")],
                new_metadata: Annotated[
                    dict, Field(description="æ–°çš„ metadataï¼Œæœƒèˆ‡ç¾æœ‰ metadata åˆä½µ")
                ],
                collection_name: Annotated[
                    str, Field(description="è¦æ›´æ–°æ–‡æª”çš„ collection åç¨±")
                ] = "default",
                confirm_update: Annotated[
                    bool, Field(description="ç¢ºèªæ›´æ–°æ“ä½œï¼Œå¿…é ˆè¨­ç‚º True")
                ] = False,
                limit: Annotated[
                    int, Field(description="æœ€å¤šæ›´æ–°çš„æ–‡æª”æ•¸é‡")
                ] = 10,
            ) -> str:
                """
                æ›´æ–°ç¬¦åˆæœå°‹æ¢ä»¶çš„æ–‡æª” metadataã€‚éœ€è¦æ˜ç¢ºç¢ºèªæ‰èƒ½åŸ·è¡Œã€‚
                """
                await ctx.debug(f"Updating metadata for documents matching '{query}' in collection '{collection_name}'")
                
                result = await self.qdrant_connector.update_metadata(
                    query=query,
                    new_metadata=new_metadata,
                    collection_name=collection_name,
                    limit=limit,
                    confirm_update=confirm_update,
                )
                
                if "error" in result:
                    return f"éŒ¯èª¤: {result['error']}"
                
                return result["message"]

            # æ–°å¢ç§»é™¤ metadata éµå·¥å…·
            async def remove_metadata_keys(
                ctx: Context,
                query: Annotated[str, Field(description="æœå°‹è¦è™•ç†çš„æ–‡æª”")],
                keys_to_remove: Annotated[
                    list[str], Field(description="è¦ç§»é™¤çš„ metadata éµåˆ—è¡¨")
                ],
                collection_name: Annotated[
                    str, Field(description="è¦è™•ç†æ–‡æª”çš„ collection åç¨±")
                ] = "default",
                confirm_update: Annotated[
                    bool, Field(description="ç¢ºèªæ›´æ–°æ“ä½œï¼Œå¿…é ˆè¨­ç‚º True")
                ] = False,
                limit: Annotated[
                    int, Field(description="æœ€å¤šè™•ç†çš„æ–‡æª”æ•¸é‡")
                ] = 10,
            ) -> str:
                """
                å¾ç¬¦åˆæœå°‹æ¢ä»¶çš„æ–‡æª” metadata ä¸­ç§»é™¤æŒ‡å®šçš„éµã€‚éœ€è¦æ˜ç¢ºç¢ºèªæ‰èƒ½åŸ·è¡Œã€‚
                """
                await ctx.debug(f"Removing metadata keys {keys_to_remove} from documents matching '{query}' in collection '{collection_name}'")
                
                result = await self.qdrant_connector.remove_metadata_keys(
                    query=query,
                    keys_to_remove=keys_to_remove,
                    collection_name=collection_name,
                    limit=limit,
                    confirm_update=confirm_update,
                )
                
                if "error" in result:
                    return f"éŒ¯èª¤: {result['error']}"
                
                return result["message"]

            # è¨»å†Šæ–°å·¥å…·
            self.tool(
                delete_documents,
                name="qdrant-delete-documents",
                description="åˆªé™¤ç¬¦åˆæœå°‹æ¢ä»¶çš„æ–‡æª”ã€‚éœ€è¦æ˜ç¢ºç¢ºèªæ‰èƒ½åŸ·è¡Œã€‚",
            )
            
            self.tool(
                delete_collection,
                name="qdrant-delete-collection", 
                description="åˆªé™¤æ•´å€‹ collection åŠå…¶æ‰€æœ‰æ–‡æª”ã€‚éœ€è¦æ˜ç¢ºç¢ºèªæ‰èƒ½åŸ·è¡Œã€‚",
            )
            
            self.tool(
                move_documents,
                name="qdrant-move-documents",
                description="æ¬ç§»æ–‡æª”å¾ä¸€å€‹ collection åˆ°å¦ä¸€å€‹ collectionã€‚éœ€è¦æ˜ç¢ºç¢ºèªæ‰èƒ½åŸ·è¡Œã€‚",
            )

            # é‡æ–°å•Ÿç”¨ï¼Œå·²ä¿®æ­£ PointStruct å‘é‡è³‡æ–™å•é¡Œ
            self.tool(
                update_metadata,
                name="qdrant-update-metadata",
                description="æ›´æ–°ç¬¦åˆæœå°‹æ¢ä»¶çš„æ–‡æª” metadataã€‚éœ€è¦æ˜ç¢ºç¢ºèªæ‰èƒ½åŸ·è¡Œã€‚",
            )
            
            self.tool(
                remove_metadata_keys,
                name="qdrant-remove-metadata-keys",
                description="å¾ç¬¦åˆæœå°‹æ¢ä»¶çš„æ–‡æª” metadata ä¸­ç§»é™¤æŒ‡å®šçš„éµã€‚éœ€è¦æ˜ç¢ºç¢ºèªæ‰èƒ½åŸ·è¡Œã€‚",
            )

        # æ–°å¢åˆ—å‡º collections å·¥å…·ï¼ˆåªè®€æ“ä½œï¼‰
        async def list_collections(ctx: Context) -> list[str]:
            """
            åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ collectionsã€‚
            """
            await ctx.debug("Listing all collections")
            collections = await self.qdrant_connector.list_collections()
            return collections

        self.tool(
            list_collections,
            name="qdrant-list-collections",
            description="åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ collectionsã€‚",
        )

        # ç´” Qdrant API ç›£æ§å·¥å…·
        async def get_qdrant_status(ctx: Context) -> list[str]:
            """
            ç²å– Qdrant çš„ç‹€æ…‹è³‡è¨Šï¼Œåƒ…åŸºæ–¼ Qdrant è‡ªèº«çš„ APIã€‚
            """
            await ctx.debug("Getting Qdrant status via pure API")
            try:
                report = await self.system_monitor.get_comprehensive_analysis()
                
                # æ ¼å¼åŒ–å ±å‘Šç‚ºå¯è®€æ ¼å¼
                result = ["ğŸ” **Qdrant ç‹€æ…‹åˆ†æ (ç´” API ç‰ˆæœ¬)**"]
                result.append(f"ğŸ“… åˆ†ææ™‚é–“: {report['timestamp']}")
                result.append("")
                
                # éƒ¨ç½²ç’°å¢ƒè³‡è¨Š
                deployment = report.get('deployment_info', {})
                result.append("ğŸ—ï¸ **éƒ¨ç½²ç’°å¢ƒ**")
                result.append(f"   é¡å‹: {deployment.get('description', 'unknown')}")
                result.append(f"   ä¸»æ©Ÿ: {deployment.get('host', 'unknown')}")
                result.append(f"   ç«¯å£: {deployment.get('port', 'unknown')}")
                result.append(f"   å¯ç”¨åŠŸèƒ½: {', '.join(deployment.get('features', []))}")
                result.append("")
                
                # Qdrant å¥åº·ç‹€æ…‹
                health = report.get('health_status', {})
                result.append("ğŸ¥ **æœå‹™å¥åº·ç‹€æ…‹**")
                status_emoji = "âœ…" if health.get('status') == 'healthy' else "âŒ"
                result.append(f"   ç‹€æ…‹: {status_emoji} {health.get('status', 'unknown')}")
                if 'collections_count' in health:
                    result.append(f"   Collections: {health.get('collections_count', 0)} å€‹")
                if 'error' in health:
                    result.append(f"   éŒ¯èª¤: {health['error']}")
                result.append("")
                
                # Collections åˆ†æ
                collections_info = report.get('collections_info', {})
                if collections_info and 'collections' in collections_info:
                    collections = collections_info['collections']
                    summary = collections_info.get('summary', {})
                    
                    result.append("ğŸ“Š **Collections åˆ†æ**")
                    for collection in collections:
                        name = collection.get('name', 'unknown')
                        points = collection.get('points_count', 0)
                        vectors = collection.get('vectors_count', 0)
                        memory_mb = collection.get('estimated_memory_mb', 0)
                        status = collection.get('status', 'unknown')
                        
                        # æ•ˆèƒ½è©•ä¼°
                        perf_emoji = "ğŸŸ¢" if memory_mb < 100 else "ğŸŸ¡" if memory_mb < 500 else "ğŸ”´"
                        result.append(f"   ğŸ“ {name}: {points:,} points, {vectors:,} vectors, ~{memory_mb:.1f}MB {perf_emoji}")
                        result.append(f"      ç‹€æ…‹: {status}")
                        
                        # ç´¢å¼•ç‹€æ…‹
                        indexed = collection.get('indexed_vectors_count', 0)
                        if vectors > 0:
                            index_ratio = indexed / vectors
                            if index_ratio < 0.9:
                                result.append(f"      âš ï¸ ç´¢å¼•ç‡: {index_ratio:.1%} (å»ºè­°é‡æ–°ç´¢å¼•)")
                    
                    result.append("")
                    result.append("ğŸ“ˆ **ç¸½è¨ˆçµ±è¨ˆ**")
                    result.append(f"   ç¸½ Collections: {summary.get('total_collections', 0)}")
                    result.append(f"   ç¸½ Points: {summary.get('total_points', 0):,}")
                    result.append(f"   ç¸½ Vectors: {summary.get('total_vectors', 0):,}")
                    result.append(f"   ä¼°è¨ˆè¨˜æ†¶é«”: {summary.get('total_estimated_memory_mb', 0):.1f}MB")
                    result.append("")
                
                # æ€§èƒ½åˆ†æ
                performance = report.get('performance_analysis', {})
                if performance and 'error' not in performance:
                    result.append("âš¡ **æ•ˆèƒ½åˆ†æ**")
                    score = performance.get('overall_score', 'unknown')
                    score_emoji = {"excellent": "ğŸŸ¢", "good": "ğŸŸ¡", "fair": "ğŸŸ ", "poor": "ğŸ”´"}.get(score, "âšª")
                    result.append(f"   æ•´é«”è©•åˆ†: {score_emoji} {score}")
                    
                    recommendations = performance.get('recommendations', [])
                    if recommendations:
                        result.append("   ğŸ’¡ å»ºè­°:")
                        for rec in recommendations:
                            result.append(f"      â€¢ {rec}")
                    
                    indexing_issues = performance.get('indexing_issues', [])
                    if indexing_issues:
                        result.append("   âš ï¸ ç´¢å¼•å•é¡Œ:")
                        for issue in indexing_issues:
                            result.append(f"      â€¢ {issue['collection']}: {issue['issue']} ({issue['indexed_ratio']:.1%})")
                    result.append("")
                
                # é›†ç¾¤è³‡è¨Š
                cluster = report.get('cluster_info', {})
                if cluster and 'error' not in cluster:
                    result.append("ğŸŒ **é›†ç¾¤è³‡è¨Š**")
                    if cluster.get('status') == 'healthy':
                        result.append("   ç‹€æ…‹: âœ… å¥åº·")
                    result.append("")
                
                # ç›£æ§ç¯„åœèªªæ˜
                result.append("â„¹ï¸ **ç›£æ§ç¯„åœ**")
                result.append(f"   ç›£æ§é¡å‹: {report.get('monitoring_scope', 'unknown')}")
                limitations = report.get('limitations', [])
                if limitations:
                    result.append("   é™åˆ¶:")
                    for limitation in limitations:
                        result.append(f"      â€¢ {limitation}")
                
                return result
                
            except Exception as e:
                logger.error(f"ç²å– Qdrant ç‹€æ…‹å¤±æ•—: {e}")
                return [
                    "âŒ **Qdrant ç‹€æ…‹åˆ†æå¤±æ•—**",
                    f"éŒ¯èª¤: {str(e)}",
                    "",
                    "é€™å¯èƒ½æ˜¯å› ç‚º:",
                    "â€¢ Qdrant æœå‹™æœªé‹è¡Œ",
                    "â€¢ é€£æ¥é…ç½®éŒ¯èª¤", 
                    "â€¢ ç¶²è·¯å•é¡Œ"
                ]

        async def get_qdrant_performance(ctx: Context) -> list[str]:
            """
            ç²å– Qdrant çš„æ•ˆèƒ½åˆ†æï¼Œåƒ…åŸºæ–¼ Qdrant API è³‡æ–™ã€‚
            """
            await ctx.debug("Getting Qdrant performance analysis")
            try:
                collections_info = await self.system_monitor.get_collections_info()
                performance = self.system_monitor._analyze_performance(collections_info)
                
                result = ["ğŸ“Š **Qdrant æ•ˆèƒ½åˆ†æ**"]
                result.append("")
                
                if 'error' in performance:
                    result.append(f"âŒ åˆ†æå¤±æ•—: {performance['error']}")
                    return result
                    
                # æ•´é«”æ•ˆèƒ½è©•åˆ†
                score = performance.get('overall_score', 'unknown')
                score_emoji = {"excellent": "ğŸŸ¢", "good": "ğŸŸ¡", "fair": "ğŸŸ ", "poor": "ğŸ”´"}.get(score, "âšª")
                result.append(f"âš¡ **æ•´é«”æ•ˆèƒ½**: {score_emoji} {score}")
                result.append("")
                
                # è¨˜æ†¶é«”åˆ†æ
                total_memory = performance.get('total_estimated_memory_mb', 0)
                total_vectors = performance.get('total_vectors', 0)
                result.append("ğŸ’¾ **è¨˜æ†¶é«”åˆ†æ**")
                result.append(f"   ä¼°è¨ˆç¸½è¨˜æ†¶é«”: {total_memory:.1f} MB")
                result.append(f"   ç¸½å‘é‡æ•¸: {total_vectors:,}")
                if total_vectors > 0:
                    avg_memory_per_vector = (total_memory * 1024) / total_vectors  # KB per vector
                    result.append(f"   å¹³å‡æ¯å‘é‡: {avg_memory_per_vector:.2f} KB")
                result.append("")
                
                # Collection æ•ˆèƒ½åˆ†æ
                collection_analysis = performance.get('collection_analysis', [])
                if collection_analysis:
                    result.append("ï¿½ **Collection æ•ˆèƒ½**")
                    for analysis in collection_analysis:
                        name = analysis.get('name', 'unknown')
                        efficiency = analysis.get('efficiency', 'unknown')
                        indexed_ratio = analysis.get('indexed_ratio', 0)
                        
                        eff_emoji = {"good": "ğŸŸ¢", "fair": "ğŸŸ¡", "poor": "ğŸ”´"}.get(efficiency, "âšª")
                        result.append(f"   ğŸ“‚ {name}:")
                        result.append(f"      æ•ˆç‡: {eff_emoji} {efficiency}")
                        result.append(f"      ç´¢å¼•ç‡: {indexed_ratio:.1%}")
                result.append("")
                
                # å»ºè­°
                recommendations = performance.get('recommendations', [])
                if recommendations:
                    result.append("ğŸ’¡ **æœ€ä½³åŒ–å»ºè­°**")
                    for i, rec in enumerate(recommendations, 1):
                        result.append(f"   {i}. {rec}")
                    result.append("")
                
                # ç´¢å¼•å•é¡Œ
                indexing_issues = performance.get('indexing_issues', [])
                if indexing_issues:
                    result.append("âš ï¸ **ç´¢å¼•å•é¡Œ**")
                    for issue in indexing_issues:
                        result.append(f"   â€¢ {issue['collection']}: {issue['issue']} (ç´¢å¼•ç‡: {issue['indexed_ratio']:.1%})")
                    result.append("")
                
                result.append("â„¹ï¸ **èªªæ˜**: æ­¤åˆ†æåƒ…åŸºæ–¼ Qdrant API æä¾›çš„è³‡è¨Š")
                
                return result
                
            except Exception as e:
                logger.error(f"ç²å–æ•ˆèƒ½åˆ†æå¤±æ•—: {e}")
                return [
                    "âŒ **æ•ˆèƒ½åˆ†æå¤±æ•—**",
                    f"éŒ¯èª¤: {str(e)}"
                ]

        async def get_collections_detailed_analysis(ctx: Context) -> list[str]:
            """
            ç²å– Collections çš„è©³ç´°åˆ†æï¼ŒåŒ…æ‹¬æ•ˆèƒ½è©•ä¼°å’Œæœ€ä½³åŒ–å»ºè­°ã€‚
            """
            await ctx.debug("Getting detailed collections analysis")
            try:
                collections_info = await self.system_monitor.get_collections_info()
                
                if not collections_info or 'collections' not in collections_info:
                    return ["ğŸ“‹ æ²’æœ‰ç™¼ç¾ä»»ä½• Collections"]
                
                result = ["ğŸ“Š **Collections è©³ç´°åˆ†æ**"]
                result.append("")
                
                for collection in collections_info['collections']:
                    if isinstance(collection, dict) and 'name' in collection:
                        if 'error' in collection:
                            result.append(f"âŒ **{collection['name']}** - åˆ†æå¤±æ•—: {collection['error']}")
                            continue
                        
                        result.append(f"ğŸ“ **Collection: {collection['name']}**")
                        
                        # åŸºæœ¬çµ±è¨ˆ
                        result.append("   ğŸ“ˆ çµ±è¨ˆè³‡è¨Š:")
                        result.append(f"      Points: {collection.get('points_count', 0):,}")
                        result.append(f"      Vectors: {collection.get('vectors_count', 0):,}")
                        result.append(f"      å·²ç´¢å¼•: {collection.get('indexed_vectors_count', 0):,}")
                        
                        # è¨ˆç®—ç´¢å¼•ç‡
                        vectors_count = collection.get('vectors_count', 0)
                        indexed_count = collection.get('indexed_vectors_count', 0)
                        indexing_ratio = indexed_count / vectors_count if vectors_count > 0 else 0
                        result.append(f"      ç´¢å¼•ç‡: {indexing_ratio:.1%}")
                        
                        # å‘é‡é…ç½®
                        vector_size = collection.get('vector_size', 0)
                        if vector_size > 0:
                            result.append("   ğŸ”§ å‘é‡é…ç½®:")
                            result.append(f"      å‘é‡ç¶­åº¦: {vector_size} ç¶­")
                        
                        # è¨˜æ†¶é«”åˆ†æ
                        memory_mb = collection.get('estimated_memory_mb', 0)
                        result.append("   ğŸ§  è¨˜æ†¶é«”åˆ†æ:")
                        result.append(f"      ç¸½ä¼°ç®—: {memory_mb:.2f} MB")
                        if collection.get('points_count', 0) > 0:
                            memory_per_point = memory_mb / collection['points_count']
                            result.append(f"      æ¯é»è¨˜æ†¶é«”: {memory_per_point:.4f} MB")
                        
                        # ç‹€æ…‹è³‡è¨Š
                        status = collection.get('status', 'unknown')
                        result.append("   âš™ï¸ ç‹€æ…‹:")
                        result.append(f"      Collection: {status}")
                        
                        result.append("")
                
                return result
                
            except Exception as e:
                logger.error(f"Failed to get collections analysis: {e}")
                return [f"âŒ ç²å– Collections åˆ†æå¤±æ•—: {str(e)}"]

        async def get_deployment_info(ctx: Context) -> list[str]:
            """
            ç²å–éƒ¨ç½²ç’°å¢ƒè³‡è¨Šå’Œæ”¯æ´çš„åŠŸèƒ½ã€‚
            """
            await ctx.debug("Getting deployment information")
            try:
                deployment_info = self.system_monitor.deployment_info
                
                result = ["ğŸ—ï¸ **éƒ¨ç½²ç’°å¢ƒè³‡è¨Š**"]
                result.append("")
                
                result.append(f"ï¿½ **åŸºæœ¬è³‡è¨Š**")
                result.append(f"   é¡å‹: {deployment_info.get('type', 'unknown')}")
                result.append(f"   ä¸»æ©Ÿ: {deployment_info.get('host', 'unknown')}")
                result.append(f"   ç«¯å£: {deployment_info.get('port', 'unknown')}")
                result.append("")
                
                result.append(f"ğŸ”§ **ç’°å¢ƒç‰¹æ€§**")
                result.append(f"   æœ¬åœ°éƒ¨ç½²: {'âœ…' if deployment_info.get('is_local') else 'âŒ'}")
                result.append(f"   é›²ç«¯æœå‹™: {'âœ…' if deployment_info.get('is_cloud') else 'âŒ'}")
                result.append(f"   Docker å®¹å™¨: {'âœ…' if deployment_info.get('is_docker') else 'âŒ'}")
                result.append("")
                
                # å¯ç”¨åŠŸèƒ½
                features = deployment_info.get('features', [])
                result.append(f"âœ¨ **å¯ç”¨åŠŸèƒ½** ({len(features)} é …)")
                feature_descriptions = {
                    'qdrant_api': 'ğŸ”Œ Qdrant API æŸ¥è©¢',
                    'health_check': 'ğŸ¥ å¥åº·ç‹€æ…‹æª¢æŸ¥',
                    'collections_stats': 'ğŸ“Š Collections çµ±è¨ˆ',
                    'system_metrics': 'ğŸ’» ç³»çµ±è³‡æºç›£æ§',
                    'docker_stats': 'ğŸ³ Docker å®¹å™¨ç›£æ§',
                    'container_logs': 'ğŸ“‹ å®¹å™¨æ—¥èªŒæŸ¥çœ‹'
                }
                
                for feature in features:
                    desc = feature_descriptions.get(feature, f'ğŸ”§ {feature}')
                    result.append(f"   {desc}")
                result.append("")
                
                # é™åˆ¶
                limitations = deployment_info.get('limitations', [])
                if limitations:
                    result.append(f"âš ï¸ **åŠŸèƒ½é™åˆ¶** ({len(limitations)} é …)")
                    limitation_descriptions = {
                        'no_system_metrics': 'ğŸ’» ç„¡æ³•ç²å–ç³»çµ±è³‡æºè³‡è¨Š',
                        'no_container_access': 'ğŸ³ ç„¡æ³•å­˜å–å®¹å™¨è³‡è¨Š',
                        'no_logs_access': 'ğŸ“‹ ç„¡æ³•ç²å–æœå‹™æ—¥èªŒ',
                        'no_docker_stats': 'ğŸ“Š ç„¡æ³•ç²å– Docker çµ±è¨ˆ'
                    }
                    
                    for limitation in limitations:
                        desc = limitation_descriptions.get(limitation, f'âš ï¸ {limitation}')
                        result.append(f"   {desc}")
                    result.append("")
                
                # éƒ¨ç½²å»ºè­°
                deployment_type = deployment_info.get('type', 'unknown')
                result.append("ğŸ’¡ **éƒ¨ç½²å»ºè­°**")
                
                if deployment_type == 'cloud':
                    result.append("   â€¢ é›²ç«¯éƒ¨ç½²ï¼šé—œæ³¨æˆæœ¬æœ€ä½³åŒ–å’Œè³‡æ–™å‚³è¼¸")
                    result.append("   â€¢ å»ºè­°è¨­å®šé©ç•¶çš„æŸ¥è©¢é™åˆ¶å’Œå¿«å–ç­–ç•¥")
                    result.append("   â€¢ å®šæœŸæª¢æŸ¥ API ä½¿ç”¨é‡å’Œè¨ˆè²»")
                elif deployment_type == 'docker_local':
                    result.append("   â€¢ Docker éƒ¨ç½²ï¼šç›£æ§å®¹å™¨è³‡æºä½¿ç”¨")
                    result.append("   â€¢ å»ºè­°è¨­å®šè¨˜æ†¶é«”é™åˆ¶å’Œå¥åº·æª¢æŸ¥")
                    result.append("   â€¢ å®šæœŸå‚™ä»½è³‡æ–™å’Œé…ç½®")
                elif deployment_type == 'local_binary':
                    result.append("   â€¢ æœ¬åœ°éƒ¨ç½²ï¼šæ³¨æ„ç³»çµ±è³‡æºç®¡ç†")
                    result.append("   â€¢ å»ºè­°è¨­å®šé©ç•¶çš„ç³»çµ±ç›£æ§")
                    result.append("   â€¢ ç¢ºä¿è³‡æ–™å‚™ä»½å’Œæœå‹™è‡ªå‹•é‡å•Ÿ")
                else:
                    result.append("   â€¢ å»ºè­°æ ¹æ“šå¯¦éš›éœ€æ±‚é¸æ“‡åˆé©çš„ç›£æ§ç­–ç•¥")
                
                return result
                
            except Exception as e:
                logger.error(f"Failed to get deployment info: {e}")
                return [f"âŒ ç²å–éƒ¨ç½²è³‡è¨Šå¤±æ•—: {str(e)}"]

        async def get_docker_containers(ctx: Context) -> list[str]:
            """
            ç²å– Qdrant ç›¸é—œçš„ Docker å®¹å™¨è³‡è¨Šã€‚
            """
            await ctx.debug("Getting Docker containers info")
            try:
                from .system_monitor_backup import DockerSystemMonitor
                containers = DockerSystemMonitor.list_qdrant_containers()
                
                if not containers:
                    return ["ğŸ“¦ æ²’æœ‰ç™¼ç¾ Qdrant ç›¸é—œçš„ Docker å®¹å™¨"]
                
                result = ["ğŸ³ **Qdrant Docker å®¹å™¨**"]
                result.append("")
                
                for container in containers:
                    result.append(f"ğŸ“¦ **å®¹å™¨: {container.get('name', 'unknown')}**")
                    result.append(f"   ç‹€æ…‹: {container.get('status', 'unknown')}")
                    result.append(f"   æ˜ åƒ: {container.get('image', 'unknown')}")
                    result.append(f"   ç«¯å£: {container.get('ports', 'none')}")
                    result.append("")
                
                return result
                
            except Exception as e:
                logger.error(f"Failed to get Docker containers: {e}")
                return [f"âŒ ç²å– Docker å®¹å™¨è³‡è¨Šå¤±æ•—: {str(e)}"]

        async def get_container_logs(
            ctx: Context,
            container_name: Annotated[str, Field(description="å®¹å™¨åç¨±")] = "qdrant",
            lines: Annotated[int, Field(description="æ—¥èªŒè¡Œæ•¸")] = 50
        ) -> list[str]:
            """
            ç²å–æŒ‡å®šå®¹å™¨çš„æ—¥èªŒã€‚
            """
            await ctx.debug(f"Getting container logs for {container_name}")
            try:
                from .system_monitor_backup import DockerSystemMonitor
                logs = DockerSystemMonitor.get_container_logs(container_name, lines)
                
                result = [f"ğŸ“‹ **å®¹å™¨æ—¥èªŒ: {container_name} (æœ€è¿‘ {lines} è¡Œ)**"]
                result.append("```")
                result.append(logs)
                result.append("```")
                
                return result
                
            except Exception as e:
                logger.error(f"Failed to get container logs: {e}")
                return [f"âŒ ç²å–å®¹å™¨æ—¥èªŒå¤±æ•—: {str(e)}"]

        # è¨»å†Šé€šç”¨ç³»çµ±ç›£æ§å·¥å…·
        async def get_qdrant_status(ctx: Context) -> list[str]:
            """
            ç²å– Qdrant çš„ç¶œåˆç‹€æ…‹è³‡è¨Šï¼Œè‡ªå‹•é©æ‡‰æ‰€æœ‰éƒ¨ç½²æ–¹å¼ã€‚
            æ”¯æ´ Cloudã€Dockerã€Localã€Remote ç­‰å¤šç¨®éƒ¨ç½²ç’°å¢ƒã€‚
            """
            await ctx.debug("Getting comprehensive Qdrant status")
            
            try:
                status = await self.system_monitor.get_comprehensive_analysis()
                
                result = ["ğŸ” **Qdrant ç¶œåˆç‹€æ…‹åˆ†æ**"]
                result.append("")
                
                # éƒ¨ç½²è³‡è¨Š
                deployment = status.get("deployment_info", {})
                result.append(f"ğŸ“Š **éƒ¨ç½²é¡å‹**: {deployment.get('type', 'unknown')}")
                result.append(f"ğŸŒ **ç«¯é»**: {deployment.get('url', 'unknown')}")
                result.append(f"ğŸ  **ä¸»æ©Ÿ**: {deployment.get('host', 'unknown')}:{deployment.get('port', 'unknown')}")
                result.append("")
                
                # å¯ç”¨åŠŸèƒ½
                features = deployment.get("features", [])
                result.append("âœ… **å¯ç”¨åŠŸèƒ½**:")
                for feature in features:
                    result.append(f"   â€¢ {feature}")
                result.append("")
                
                # é™åˆ¶èªªæ˜
                limitations = deployment.get("limitations", [])
                if limitations:
                    result.append("âš ï¸ **åŠŸèƒ½é™åˆ¶**:")
                    for limitation in limitations:
                        result.append(f"   â€¢ {limitation}")
                    result.append("")
                
                # Qdrant å¥åº·ç‹€æ…‹
                health = status.get("qdrant_health", {})
                result.append(f"ğŸ’š **Qdrant ç‹€æ…‹**: {health.get('status', 'unknown')}")
                result.append(f"ğŸ“ **Collections æ•¸é‡**: {health.get('collections_count', 0)}")
                
                # æ¨£æœ¬ Collection ç‹€æ…‹
                if "sample_collection_status" in health:
                    sample = health["sample_collection_status"]
                    result.append(f"ğŸ“‚ **æ¨£æœ¬ Collection**: {sample.get('name', 'unknown')}")
                    result.append(f"   â€¢ æ–‡ä»¶æ•¸é‡: {sample.get('points_count', 0)}")
                    result.append(f"   â€¢ ç‹€æ…‹: {sample.get('status', 'unknown')}")
                result.append("")
                
                # ç³»çµ±æŒ‡æ¨™ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                system_metrics = status.get("system_metrics", {})
                if not system_metrics.get("unavailable"):
                    result.append("ğŸ’» **ç³»çµ±è³‡æº**:")
                    if "cpu" in system_metrics:
                        cpu = system_metrics["cpu"]
                        result.append(f"   â€¢ CPU: {cpu.get('usage_percent', 0)}% ({cpu.get('core_count', 0)} æ ¸å¿ƒ)")
                    if "memory" in system_metrics:
                        memory = system_metrics["memory"]
                        result.append(f"   â€¢ è¨˜æ†¶é«”: {memory.get('usage_percent', 0)}% ({memory.get('used_gb', 0):.1f}GB / {memory.get('total_gb', 0):.1f}GB)")
                    if "disk" in system_metrics:
                        disk = system_metrics["disk"]
                        result.append(f"   â€¢ ç£ç¢Ÿ: {disk.get('usage_percent', 0)}% ({disk.get('used_gb', 0):.1f}GB / {disk.get('total_gb', 0):.1f}GB)")
                else:
                    result.append("ğŸ’» **ç³»çµ±è³‡æº**: ä¸å¯ç”¨")
                    result.append(f"   åŸå› : {system_metrics.get('reason', 'unknown')}")
                    if "alternatives" in system_metrics:
                        result.append("   ğŸ’¡ **æ›¿ä»£æ–¹æ¡ˆ**:")
                        for alt in system_metrics["alternatives"]:
                            result.append(f"      â€¢ {alt}")
                result.append("")
                
                # Docker æŒ‡æ¨™ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                docker_metrics = status.get("docker_metrics", {})
                if not docker_metrics.get("unavailable"):
                    result.append("ğŸ³ **Docker å®¹å™¨**:")
                    result.append(f"   â€¢ å®¹å™¨: {docker_metrics.get('container_name', 'unknown')}")
                    result.append(f"   â€¢ CPU: {docker_metrics.get('cpu_percent', 'unknown')}")
                    result.append(f"   â€¢ è¨˜æ†¶é«”: {docker_metrics.get('memory_usage', 'unknown')} ({docker_metrics.get('memory_percent', 'unknown')})")
                    result.append(f"   â€¢ ç¶²è·¯ I/O: {docker_metrics.get('network_io', 'unknown')}")
                else:
                    result.append("ğŸ³ **Docker æŒ‡æ¨™**: ä¸å¯ç”¨")
                    result.append(f"   åŸå› : {docker_metrics.get('reason', 'unknown')}")
                result.append("")
                
                # é›²ç«¯è³‡è¨Šï¼ˆå¦‚æœæ˜¯é›²ç«¯éƒ¨ç½²ï¼‰
                if "cloud_info" in status:
                    cloud = status["cloud_info"]
                    result.append("â˜ï¸ **é›²ç«¯æœå‹™è³‡è¨Š**:")
                    result.append(f"   â€¢ æä¾›å•†: {cloud.get('provider', 'unknown')}")
                    if "dashboard_url" in cloud:
                        result.append(f"   â€¢ æ§åˆ¶å°: {cloud['dashboard_url']}")
                    if "features" in cloud:
                        result.append("   â€¢ é›²ç«¯åŠŸèƒ½:")
                        for feature in cloud["features"]:
                            result.append(f"      â€¢ {feature}")
                    result.append("")
                
                # é ç«¯éƒ¨ç½²å»ºè­°ï¼ˆå¦‚æœæ˜¯é ç«¯éƒ¨ç½²ï¼‰
                if "remote_monitoring_suggestions" in status:
                    result.append("ğŸ”— **é ç«¯ç›£æ§å»ºè­°**:")
                    for suggestion in status["remote_monitoring_suggestions"]:
                        result.append(f"   â€¢ {suggestion}")
                    result.append("")
                
                result.append(f"ğŸ• **æ›´æ–°æ™‚é–“**: {status.get('timestamp', 'unknown')}")
                
                return result
                
            except Exception as e:
                logger.error(f"Failed to get Qdrant status: {e}")
                return [f"âŒ ç²å–ç‹€æ…‹å¤±æ•—: {str(e)}"]

        async def get_collections_detailed_analysis(ctx: Context) -> list[str]:
            """
            ç²å– Collections çš„è©³ç´°æ•ˆèƒ½åˆ†æï¼ŒåŒ…æ‹¬éƒ¨ç½²ç‰¹å®šçš„æœ€ä½³åŒ–å»ºè­°ã€‚
            """
            await ctx.debug("Getting detailed collections analysis")
            
            try:
                analytics = await self.system_monitor.get_collections_info()
                
                result = ["ğŸ“Š **Collections è©³ç´°åˆ†æ**"]
                result.append("")
                
                if not analytics or 'collections' not in analytics:
                    result.append("âŒ ç„¡æ³•ç²å– Collections è³‡è¨Š")
                    return result
                
                for collection in analytics['collections']:
                    if "error" in collection:
                        result.append(f"âŒ **{collection.get('name', 'unknown')}**: {collection['error']}")
                        continue
                    
                    result.append(f"ğŸ“ **Collection: {collection['name']}**")
                    
                    # åŸºæœ¬çµ±è¨ˆ
                    result.append(f"   ğŸ“ˆ **çµ±è¨ˆè³‡æ–™**:")
                    result.append(f"      â€¢ æ–‡ä»¶æ•¸: {collection.get('points_count', 0):,}")
                    result.append(f"      â€¢ å‘é‡æ•¸: {collection.get('vectors_count', 0):,}")
                    result.append(f"      â€¢ å·²ç´¢å¼•å‘é‡: {collection.get('indexed_vectors_count', 0):,}")
                    
                    # è¨ˆç®—ç´¢å¼•ç‡
                    vectors_count = collection.get('vectors_count', 0)
                    indexed_count = collection.get('indexed_vectors_count', 0)
                    indexing_ratio = indexed_count / vectors_count if vectors_count > 0 else 0
                    result.append(f"      â€¢ ç´¢å¼•ç‡: {indexing_ratio:.1%}")
                    
                    # è¨˜æ†¶é«”ä¼°ç®—
                    memory_mb = collection.get('estimated_memory_mb', 0)
                    result.append(f"      â€¢ è¨˜æ†¶é«”ä¼°ç®—: {memory_mb:.1f}MB")
                    
                    # å‘é‡é…ç½®
                    vector_size = collection.get('vector_size', 0)
                    if vector_size > 0:
                        result.append(f"   ğŸ¯ **å‘é‡é…ç½®**:")
                        result.append(f"      â€¢ å‘é‡ç¶­åº¦: {vector_size}")
                    
                    # ç‹€æ…‹è³‡è¨Š
                    status = collection.get('status', 'unknown')
                    result.append(f"   ğŸ’š **ç‹€æ…‹**: {status}")
                    result.append("")
                    
                    # è¨˜æ†¶é«”åˆ†æ
                    memory = collection.get("memory_analysis", {})
                    result.append(f"   ğŸ’¾ **è¨˜æ†¶é«”åˆ†æ**:")
                    result.append(f"      â€¢ ç¸½è¨ˆ: {memory.get('total_estimate_mb', 0):.1f}MB")
                    result.append(f"      â€¢ æ¯æ–‡ä»¶: {memory.get('memory_per_point_mb', 0):.3f}MB")
                    result.append(f"      â€¢ æ•ˆèƒ½è©•åˆ†: {memory.get('performance_score', 'unknown')}")
                    
                    # å»ºè­°
                    recommendations = collection.get("recommendations", [])
                    if recommendations:
                        result.append(f"   ğŸ’¡ **æœ€ä½³åŒ–å»ºè­°**:")
                        for rec in recommendations:
                            result.append(f"      â€¢ {rec}")
                    
                    # éƒ¨ç½²ç‰¹å®šæœ€ä½³åŒ–
                    deploy_opts = collection.get("deployment_optimizations", [])
                    if deploy_opts:
                        result.append(f"   ğŸš€ **éƒ¨ç½²æœ€ä½³åŒ–**:")
                        for opt in deploy_opts:
                            result.append(f"      â€¢ {opt}")
                    
                    result.append("")
                
                return result
                
            except Exception as e:
                logger.error(f"Failed to get collections analysis: {e}")
                return [f"âŒ ç²å–åˆ†æå¤±æ•—: {str(e)}"]

        async def get_deployment_info(ctx: Context) -> list[str]:
            """
            ç²å–è©³ç´°çš„éƒ¨ç½²ç’°å¢ƒè³‡è¨Šå’ŒåŠŸèƒ½æ”¯æ´ç‹€æ³ã€‚
            """
            await ctx.debug("Getting deployment information")
            
            try:
                deployment = self.system_monitor.deployment_info
                
                result = ["ğŸ—ï¸ **éƒ¨ç½²ç’°å¢ƒè©³ç´°è³‡è¨Š**"]
                result.append("")
                
                result.append(f"ğŸ“ **åŸºæœ¬è³‡è¨Š**:")
                result.append(f"   â€¢ éƒ¨ç½²é¡å‹: {deployment.get('type', 'unknown')}")
                result.append(f"   â€¢ ä¸»æ©Ÿ: {deployment.get('host', 'unknown')}")
                result.append(f"   â€¢ ç«¯å£: {deployment.get('port', 'unknown')}")
                result.append(f"   â€¢ URL: {deployment.get('url', 'unknown')}")
                result.append("")
                
                result.append(f"ğŸ“Š **éƒ¨ç½²ç‰¹æ€§**:")
                result.append(f"   â€¢ æœ¬åœ°éƒ¨ç½²: {'âœ…' if deployment.get('is_local') else 'âŒ'}")
                result.append(f"   â€¢ é›²ç«¯éƒ¨ç½²: {'âœ…' if deployment.get('is_cloud') else 'âŒ'}")
                result.append(f"   â€¢ Docker éƒ¨ç½²: {'âœ…' if deployment.get('is_docker') else 'âŒ'}")
                result.append(f"   â€¢ é ç«¯éƒ¨ç½²: {'âœ…' if deployment.get('is_remote') else 'âŒ'}")
                result.append("")
                
                features = deployment.get("features", [])
                result.append("âœ… **æ”¯æ´åŠŸèƒ½**:")
                if features:
                    for feature in features:
                        feature_name = {
                            "qdrant_api": "Qdrant API å­˜å–",
                            "health_check": "å¥åº·æª¢æŸ¥",
                            "collections_stats": "Collections çµ±è¨ˆ",
                            "system_metrics": "ç³»çµ±è³‡æºç›£æ§",
                            "docker_stats": "Docker å®¹å™¨ç›£æ§",
                            "container_logs": "å®¹å™¨æ—¥èªŒå­˜å–",
                            "container_metrics": "å®¹å™¨æŒ‡æ¨™",
                            "cloud_monitoring": "é›²ç«¯ç›£æ§åŠŸèƒ½"
                        }.get(feature, feature)
                        result.append(f"   â€¢ {feature_name}")
                else:
                    result.append("   â€¢ ç„¡ç‰¹æ®ŠåŠŸèƒ½")
                result.append("")
                
                limitations = deployment.get("limitations", [])
                if limitations:
                    result.append("âš ï¸ **åŠŸèƒ½é™åˆ¶**:")
                    for limitation in limitations:
                        limitation_name = {
                            "no_system_metrics": "ç„¡æ³•å–å¾—ç³»çµ±è³‡æºæŒ‡æ¨™",
                            "no_container_access": "ç„¡æ³•å­˜å–å®¹å™¨è³‡è¨Š",
                            "no_logs_access": "ç„¡æ³•å­˜å–æ—¥èªŒæª”æ¡ˆ",
                            "no_container_logs": "ç„¡æ³•å­˜å–å®¹å™¨æ—¥èªŒ"
                        }.get(limitation, limitation)
                        result.append(f"   â€¢ {limitation_name}")
                    result.append("")
                
                # ç›£æ§å»ºè­°
                result.append("ğŸ’¡ **ç›£æ§å»ºè­°**:")
                if deployment.get('is_cloud'):
                    result.append("   â€¢ ä½¿ç”¨é›²ç«¯æœå‹™å•†çš„ç›£æ§å·¥å…·")
                    result.append("   â€¢ è¨­å®š API ä½¿ç”¨é‡å‘Šè­¦")
                    result.append("   â€¢ ç›£æ§æˆæœ¬å’Œé…é¡")
                elif deployment.get('is_docker'):
                    result.append("   â€¢ ä½¿ç”¨ Docker å¥åº·æª¢æŸ¥")
                    result.append("   â€¢ ç›£æ§å®¹å™¨è³‡æºä½¿ç”¨")
                    result.append("   â€¢ è¨­å®šé©ç•¶çš„é‡å•Ÿç­–ç•¥")
                elif deployment.get('is_local'):
                    result.append("   â€¢ ç›£æ§æœ¬åœ°ç³»çµ±è³‡æº")
                    result.append("   â€¢ è¨­å®šæœå‹™ç®¡ç†å’Œè‡ªå‹•å•Ÿå‹•")
                    result.append("   â€¢ å®šæœŸå‚™ä»½è³‡æ–™")
                else:
                    result.append("   â€¢ ç›£æ§ç¶²è·¯é€£ç·šå“è³ª")
                    result.append("   â€¢ è¨­å®šå¥åº·æª¢æŸ¥ç«¯é»")
                    result.append("   â€¢ ä½¿ç”¨å¤–éƒ¨ç›£æ§æœå‹™")
                
                return result
                
            except Exception as e:
                logger.error(f"Failed to get deployment info: {e}")
                return [f"âŒ ç²å–éƒ¨ç½²è³‡è¨Šå¤±æ•—: {str(e)}"]

        # è¨»å†Šç´” Qdrant API ç›£æ§å·¥å…·
        self.tool(
            get_qdrant_status,
            name="qdrant-system-status",
            description="ç²å– Qdrant çš„ç‹€æ…‹è³‡è¨Šï¼Œç´”åŸºæ–¼ Qdrant APIï¼Œé©ç”¨æ‰€æœ‰éƒ¨ç½²æ–¹å¼ã€‚",
        )
        
        self.tool(
            get_qdrant_performance,
            name="qdrant-performance-analysis",
            description="ç²å– Qdrant çš„æ•ˆèƒ½åˆ†æï¼ŒåŸºæ–¼ Qdrant API è³‡æ–™æä¾›è¨˜æ†¶é«”ä½¿ç”¨å’Œæ•ˆèƒ½è©•ä¼°ã€‚",
        )

        # æ–°å¢å„²å­˜å„ªåŒ–å·¥å…·
        async def optimize_storage(
            ctx: Context,
            collection_name: Annotated[
                str, Field(description="è¦å„ªåŒ–çš„ collection åç¨±ï¼Œè¨­ç‚º 'all' è¡¨ç¤ºå„ªåŒ–æ‰€æœ‰ collections")
            ] = "all",
            confirm_optimize: Annotated[
                bool, Field(description="ç¢ºèªå„ªåŒ–æ“ä½œï¼Œå¿…é ˆè¨­ç‚º True")
            ] = False,
        ) -> list[str]:
            """
            å„ªåŒ–æŒ‡å®š collection æˆ–æ‰€æœ‰ collections çš„å„²å­˜é…ç½®ï¼Œæ¸›å°‘ç£ç¢Ÿä½¿ç”¨ã€‚éœ€è¦æ˜ç¢ºç¢ºèªæ‰èƒ½åŸ·è¡Œã€‚
            """
            await ctx.debug(f"Optimizing storage for collection '{collection_name}'")
            
            if not confirm_optimize:
                return [
                    "âŒ **å„²å­˜å„ªåŒ–è¢«å–æ¶ˆ**",
                    "",
                    "è«‹è¨­å®š confirm_optimize=True ä¾†ç¢ºèªåŸ·è¡Œå„²å­˜å„ªåŒ–ã€‚",
                    "",
                    "âš ï¸ **æ³¨æ„**: å„ªåŒ–å¾Œå»ºè­°é‡å•Ÿ Qdrant container ä»¥å®Œå…¨æ‡‰ç”¨è®Šæ›´ã€‚"
                ]
            
            try:
                if collection_name == "all":
                    result = await self.storage_optimizer.optimize_all_collections()
                else:
                    result = await self.storage_optimizer.optimize_collection_storage(collection_name)
                
                if not result.get("success", False):
                    return [
                        f"âŒ **å„²å­˜å„ªåŒ–å¤±æ•—**",
                        f"éŒ¯èª¤: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}"
                    ]
                
                # æ ¼å¼åŒ–æˆåŠŸçµæœ
                formatted_result = ["âœ… **Qdrant å„²å­˜å„ªåŒ–å®Œæˆ**"]
                formatted_result.append("")
                
                if collection_name == "all":
                    # æ‰¹æ¬¡å„ªåŒ–çµæœ
                    summary = result.get("summary", {})
                    formatted_result.append("ğŸ“Š **å„ªåŒ–ç¸½çµ**")
                    formatted_result.append(f"   Collections å„ªåŒ–: {result.get('collections_optimized', 0)}/{result.get('total_collections', 0)}")
                    formatted_result.append(f"   ç£ç¢Ÿç©ºé–“: {summary.get('disk_space_before_mb', 0):.1f}MB â†’ {summary.get('disk_space_after_mb', 0):.1f}MB")
                    formatted_result.append(f"   ç¯€çœç£ç¢Ÿ: {summary.get('disk_space_saved_mb', 0):.1f}MB ({summary.get('disk_space_saved_percent', 0):.1f}%)")
                    formatted_result.append(f"   è¨˜æ†¶é«”: {summary.get('ram_before_mb', 0):.1f}MB â†’ {summary.get('ram_after_mb', 0):.1f}MB")
                    formatted_result.append(f"   ç¯€çœè¨˜æ†¶é«”: {summary.get('ram_saved_mb', 0):.1f}MB ({summary.get('ram_saved_percent', 0):.1f}%)")
                    formatted_result.append("")
                    
                    # å€‹åˆ¥ collection çµæœ
                    if result.get("results"):
                        formatted_result.append("ğŸ“ **å„ Collection å„ªåŒ–çµæœ**")
                        for coll_result in result["results"]:
                            if coll_result.get("success"):
                                name = coll_result["collection"]
                                before_disk = coll_result["before"].get("disk_size", 0) / 1024 / 1024
                                after_disk = coll_result["after"].get("disk_size", 0) / 1024 / 1024
                                formatted_result.append(f"   âœ… {name}: {before_disk:.1f}MB â†’ {after_disk:.1f}MB")
                            else:
                                formatted_result.append(f"   âŒ {coll_result['collection']}: {coll_result.get('error', 'å„ªåŒ–å¤±æ•—')}")
                        formatted_result.append("")
                    
                    # å»ºè­°
                    recommendations = result.get("recommendations", [])
                    if recommendations:
                        formatted_result.append("ğŸ’¡ **å»ºè­°**")
                        for rec in recommendations:
                            formatted_result.append(f"   â€¢ {rec}")
                        formatted_result.append("")
                
                else:
                    # å–®ä¸€ collection å„ªåŒ–çµæœ
                    before = result.get("before", {})
                    after = result.get("after", {})
                    optimizations = result.get("optimizations_applied", {})
                    
                    formatted_result.append(f"ğŸ“ **Collection: {collection_name}**")
                    formatted_result.append(f"   å‘é‡æ•¸: {before.get('vectors_count', 0):,} â†’ {after.get('vectors_count', 0):,}")
                    formatted_result.append(f"   æ®µæ•¸: {before.get('segments_count', 0)} â†’ {after.get('segments_count', 0)}")
                    
                    before_disk = before.get("disk_size", 0) / 1024 / 1024
                    after_disk = after.get("disk_size", 0) / 1024 / 1024
                    formatted_result.append(f"   ç£ç¢Ÿ: {before_disk:.1f}MB â†’ {after_disk:.1f}MB")
                    
                    before_ram = before.get("ram_size", 0) / 1024 / 1024
                    after_ram = after.get("ram_size", 0) / 1024 / 1024
                    formatted_result.append(f"   è¨˜æ†¶é«”: {before_ram:.1f}MB â†’ {after_ram:.1f}MB")
                    formatted_result.append("")
                    
                    if optimizations:
                        formatted_result.append("ğŸ”§ **æ‡‰ç”¨çš„å„ªåŒ–**")
                        for key, value in optimizations.items():
                            formatted_result.append(f"   â€¢ {key}: {value}")
                        formatted_result.append("")
                
                formatted_result.append("ğŸ”„ **å¾ŒçºŒæ­¥é©Ÿ**")
                formatted_result.append("   å»ºè­°é‡å•Ÿ Qdrant Docker container ä»¥å®Œå…¨æ‡‰ç”¨æ‰€æœ‰å„ªåŒ–:")
                formatted_result.append("   ```bash")
                formatted_result.append("   docker restart <qdrant-container-name>")
                formatted_result.append("   ```")
                
                return formatted_result
                
            except Exception as e:
                logger.error(f"å„²å­˜å„ªåŒ–å¤±æ•—: {e}")
                return [
                    "âŒ **å„²å­˜å„ªåŒ–å¤±æ•—**",
                    f"éŒ¯èª¤: {str(e)}",
                    "",
                    "å¯èƒ½åŸå› :",
                    "â€¢ Qdrant æœå‹™æœªé‹è¡Œ",
                    "â€¢ é€£æ¥é…ç½®éŒ¯èª¤",
                    "â€¢ æ¬Šé™ä¸è¶³"
                ]

        async def analyze_storage(ctx: Context) -> list[str]:
            """
            åˆ†æç•¶å‰ Qdrant çš„å„²å­˜ä½¿ç”¨æƒ…æ³ï¼Œæä¾›å„ªåŒ–å»ºè­°ã€‚
            """
            await ctx.debug("Analyzing Qdrant storage usage")
            
            try:
                analysis = await self.storage_optimizer.get_storage_analysis()
                
                if "error" in analysis:
                    return [
                        "âŒ **å„²å­˜åˆ†æå¤±æ•—**",
                        f"éŒ¯èª¤: {analysis['error']}"
                    ]
                
                result = ["ğŸ“Š **Qdrant å„²å­˜ä½¿ç”¨åˆ†æ**"]
                result.append("")
                
                # ç¸½çµ
                summary = analysis.get("summary", {})
                result.append("ğŸ“ˆ **ç¸½è¨ˆçµ±è¨ˆ**")
                result.append(f"   Collections: {summary.get('total_collections', 0)} å€‹")
                result.append(f"   ç¸½å‘é‡æ•¸: {summary.get('total_vectors', 0):,}")
                result.append(f"   ç¸½ç£ç¢Ÿä½¿ç”¨: {summary.get('total_disk_mb', 0):.1f} MB")
                result.append(f"   ç¸½è¨˜æ†¶é«”ä½¿ç”¨: {summary.get('total_ram_mb', 0):.1f} MB")
                result.append(f"   {summary.get('estimated_optimization_savings', '')}")
                result.append("")
                
                # å„ Collection è©³æƒ…
                collections = analysis.get("collections", [])
                if collections:
                    result.append("ğŸ“ **å„ Collection è©³æƒ…**")
                    for coll in collections:
                        name = coll["collection"]
                        vectors = coll["vectors"]
                        segments = coll["segments"]
                        disk_mb = coll["disk_mb"]
                        ram_mb = coll["ram_mb"]
                        
                        # æ•ˆèƒ½è©•ä¼° - å®‰å…¨åœ°è™•ç† None å€¼
                        disk_mb = coll.get("disk_mb", 0) or 0
                        if disk_mb > 100:
                            perf_icon = "ğŸ”´ å¤§"
                        elif disk_mb > 50:
                            perf_icon = "ğŸŸ¡ ä¸­"
                        else:
                            perf_icon = "ğŸŸ¢ å°"
                        
                        result.append(f"   ğŸ“‚ {name}:")
                        result.append(f"      å‘é‡: {vectors:,}, æ®µ: {segments}")
                        result.append(f"      ç£ç¢Ÿ: {disk_mb:.1f}MB, è¨˜æ†¶é«”: {ram_mb:.1f}MB {perf_icon}")
                        
                        # é…ç½®æª¢æŸ¥
                        config = coll.get("config", {})
                        optimizer = config.get("optimizer", {})
                        hnsw = config.get("hnsw", {})
                        
                        # æª¢æŸ¥æ˜¯å¦éœ€è¦å„ªåŒ– - å®‰å…¨åœ°è™•ç† None å€¼
                        needs_optimization = []
                        max_segment_size = optimizer.get("max_segment_size", 100000) or 100000
                        if max_segment_size > 10000:
                            needs_optimization.append("æ®µå¤§å°éå¤§")
                        
                        memmap_threshold = optimizer.get("memmap_threshold", 10000) or 10000
                        if memmap_threshold > 2000:
                            needs_optimization.append("mmap é–¾å€¼éé«˜")
                        
                        hnsw_m = hnsw.get("m", 16) or 16
                        if hnsw_m > 12:
                            needs_optimization.append("HNSW m å€¼éå¤§")
                            
                        if not hnsw.get("on_disk", False):
                            needs_optimization.append("ç´¢å¼•æœªå­˜ç£ç¢Ÿ")
                        
                        if needs_optimization:
                            result.append(f"      âš ï¸ å»ºè­°å„ªåŒ–: {', '.join(needs_optimization)}")
                        else:
                            result.append(f"      âœ… é…ç½®è‰¯å¥½")
                    result.append("")
                
                # å„ªåŒ–å»ºè­°
                total_disk = summary.get('total_disk_mb', 0) or 0
                if total_disk > 200:
                    result.append("ğŸ’¡ **å„ªåŒ–å»ºè­°**")
                    result.append(f"   ç•¶å‰ç£ç¢Ÿä½¿ç”¨ {total_disk:.1f}MB åé«˜ï¼Œå»ºè­°åŸ·è¡Œå„²å­˜å„ªåŒ–:")
                    result.append("   â€¢ ä½¿ç”¨ qdrant-optimize-storage å·¥å…·å„ªåŒ–æ‰€æœ‰ collections")
                    result.append("   â€¢ é æœŸå¯ç¯€çœ 60-70% ç£ç¢Ÿç©ºé–“")
                    result.append("   â€¢ å„ªåŒ–å¾Œé‡å•Ÿ Qdrant container ä»¥å®Œå…¨ç”Ÿæ•ˆ")
                elif total_disk > 100:
                    result.append("ğŸ’¡ **å„ªåŒ–å»ºè­°**")
                    result.append(f"   ç£ç¢Ÿä½¿ç”¨ {total_disk:.1f}MB ä¸­ç­‰ï¼Œå¯è€ƒæ…®å„ªåŒ–:")
                    result.append("   â€¢ é‡å°å¤§å‹ collections åŸ·è¡Œå„ªåŒ–")
                    result.append("   â€¢ å®šæœŸæ¸…ç†ç„¡ç”¨è³‡æ–™")
                else:
                    result.append("âœ… **å„²å­˜ç‹€æ…‹è‰¯å¥½**")
                    result.append(f"   ç£ç¢Ÿä½¿ç”¨ {total_disk:.1f}MB åœ¨åˆç†ç¯„åœå…§")
                
                return result
                
            except Exception as e:
                logger.error(f"å„²å­˜åˆ†æå¤±æ•—: {e}")
                return [
                    "âŒ **å„²å­˜åˆ†æå¤±æ•—**",
                    f"éŒ¯èª¤: {str(e)}"
                ]

        # è¨»å†Šå„²å­˜å„ªåŒ–å·¥å…·
        if not self.qdrant_settings.read_only:
            self.tool(
                optimize_storage,
                name="qdrant-optimize-storage",
                description="å„ªåŒ– Qdrant collections çš„å„²å­˜é…ç½®ï¼Œæ¸›å°‘ç£ç¢Ÿä½¿ç”¨ç´„ 60-70%ã€‚éœ€è¦æ˜ç¢ºç¢ºèªæ‰èƒ½åŸ·è¡Œã€‚",
            )
        
        self.tool(
            analyze_storage,
            name="qdrant-analyze-storage", 
            description="åˆ†æ Qdrant çš„å„²å­˜ä½¿ç”¨æƒ…æ³ï¼Œæä¾›å„ªåŒ–å»ºè­°ã€‚",
        )
